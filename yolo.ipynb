{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Masks to YOLO Annotations\n",
    "### Dataset Format for YOLO\n",
    "YOLO requires annotations in .txt files (one per image) with bounding boxes or segmentation masks. For object detection (bounding boxes), use this format:\n",
    "```bash\n",
    "0 0.5 0.5 0.2 0.3  # class_id, x_center, y_center, width, height\n",
    "1 0.7 0.3 0.1 0.1\n",
    "```\n",
    "If your masks are binary images, use OpenCV to extract bounding boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mask_to_yolo(mask_path, output_path, class_id=0, mode='segmentation'):\n",
    "    \"\"\"\n",
    "    Convert a mask image to YOLO format annotations.\n",
    "    Args:\n",
    "        mask_path: Path to the mask image\n",
    "        output_path: Path to save the YOLO annotation\n",
    "        class_id: Class ID for the annotation (default 0)\n",
    "        mode: 'segmentation' or 'detection' (default 'segmentation')\n",
    "    \"\"\"\n",
    "    # Read the mask image\n",
    "    mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        print(f\"Could not read mask: {mask_path}\")\n",
    "        return\n",
    "    \n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Get image dimensions for normalization\n",
    "    height, width = mask.shape\n",
    "    \n",
    "    with open(output_path, 'w') as file:\n",
    "        for contour in contours:\n",
    "            if mode == 'segmentation':\n",
    "                # Handle segmentation mode\n",
    "                points = contour.squeeze()\n",
    "                if len(points.shape) < 2:  # Skip invalid contours\n",
    "                    continue\n",
    "                \n",
    "                # Normalize coordinates\n",
    "                normalized_points = points / [width, height]\n",
    "                \n",
    "                # Write points to file\n",
    "                points_str = \" \".join(f\"{x:.5f} {y:.5f}\" for x, y in normalized_points)\n",
    "                file.write(f\"{class_id} {points_str}\\n\")\n",
    "                \n",
    "            else:  # detection mode\n",
    "                # Handle detection mode (bounding box)\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                \n",
    "                # Convert to YOLO format (center coordinates + width + height)\n",
    "                center_x = (x + w/2) / width\n",
    "                center_y = (y + h/2) / height\n",
    "                norm_width = w / width\n",
    "                norm_height = h / height\n",
    "                \n",
    "                # Write bounding box to file\n",
    "                file.write(f\"{class_id} {center_x:.5f} {center_y:.5f} \"\n",
    "                          f\"{norm_width:.5f} {norm_height:.5f}\\n\")\n",
    "\n",
    "\n",
    "def process_dataset(base_path):\n",
    "    \"\"\"\n",
    "    Process the entire dataset, organizing images and generating YOLO annotations.\n",
    "    Args:\n",
    "        base_path: Base path to the dataset\n",
    "    \"\"\"\n",
    "    # Create a new base folder for processed data\n",
    "    processed_base_path = Path(base_path) / 'processed_data'\n",
    "    processed_base_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Process each split (train, valid, test)\n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        # Setup directories in the new base folder\n",
    "        split_path = processed_base_path / split\n",
    "        images_dir = split_path / 'images'\n",
    "        labels_dir = split_path / 'labels'\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        images_dir.mkdir(parents=True, exist_ok=True)\n",
    "        labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Process all mask files in the original dataset\n",
    "        original_split_path = Path(base_path) / split\n",
    "        for mask_file in original_split_path.glob('*_mask.png'):\n",
    "            # Get corresponding image name\n",
    "            image_name = mask_file.name.replace('_mask.png', '.jpg')\n",
    "            image_path = mask_file.with_name(image_name)\n",
    "            \n",
    "            try:\n",
    "                # Move image to images directory\n",
    "                shutil.copy(image_path, images_dir / image_name)\n",
    "                \n",
    "                # Create YOLO annotation\n",
    "                label_name = mask_file.stem.replace('_mask', '') + '.txt'\n",
    "                label_path = labels_dir / label_name\n",
    "                \n",
    "                # Convert mask to YOLO format\n",
    "                convert_mask_to_yolo(mask_file, label_path)\n",
    "                \n",
    "            except FileNotFoundError:\n",
    "                print(f\"Missing image file: {image_path}\")\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Usage example\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_path = Path('../Road_mask/')\n",
    "    process_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation (YOLOv8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install YOLOv8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_YAML_PATH = './data.yaml'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n-seg.pt')  # Segmentation model\n",
    "\n",
    "model.train(data=DATA_YAML_PATH, project=\"./Models\", epochs=50, imgsz=640, batch=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINED_MODEL_PATH = './Models/train/train2/weights/best.pt'\n",
    "\n",
    "TEST_IMAGE_PATH = \"../Road_mask_bkp/test/tile_12_jpg.rf.b0d051c082e97538bdd45a416fa6d93b.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(TRAINED_MODEL_PATH)\n",
    "# Predict on a single image\n",
    "image_path = TEST_IMAGE_PATH\n",
    "results = model.predict(image_path, imgsz=640, conf=0.5)\n",
    "\n",
    "\n",
    "# Visualize results\n",
    "for result in results:\n",
    "    plotted = result.plot()\n",
    "    cv2.imshow(\"Prediction\", plotted)\n",
    "    \n",
    "    # Wait for the user to press any key to close the window\n",
    "    if cv2.waitKey(0) & 0xFF == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Close the window properly after exiting the loop\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
