{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Masks to YOLO Annotations\n",
    "### Dataset Format for YOLO\n",
    "YOLO requires annotations in .txt files (one per image) with bounding boxes or segmentation masks. For object detection (bounding boxes), use this format:\n",
    "```bash\n",
    "0 0.5 0.5 0.2 0.3  # class_id, x_center, y_center, width, height\n",
    "1 0.7 0.3 0.1 0.1\n",
    "```\n",
    "If your masks are binary images, use OpenCV to extract bounding boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def mask_to_yolo(mask_path, output_txt_path, class_id, mode='segmentation'):\n",
    "    mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        print(f\"Warning: Could not read mask {mask_path}\")\n",
    "        return\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    with open(output_txt_path, 'w') as f:\n",
    "        for contour in contours:\n",
    "            if mode == 'segmentation':\n",
    "                contour = contour.squeeze()\n",
    "                if contour.ndim == 1:\n",
    "                    continue  # Skip invalid contours\n",
    "                contour_norm = contour / np.array([mask.shape[1], mask.shape[0]])\n",
    "                f.write(f\"{class_id} \" + \" \".join([f\"{x:.5f} {y:.5f}\" for x,y in contour_norm]) + \"\\n\")\n",
    "            elif mode == 'detection':\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                x_center = (x + w/2) / mask.shape[1]\n",
    "                y_center = (y + h/2) / mask.shape[0]\n",
    "                width = w / mask.shape[1]\n",
    "                height = h / mask.shape[0]\n",
    "                f.write(f\"{class_id} {x_center:.5f} {y_center:.5f} {width:.5f} {height:.5f}\\n\")\n",
    "\n",
    "# Process all splits (match your folder names: train, valid, test)\n",
    "for split in ['train', 'valid', 'test']:  # Fixed 'val' -> 'valid'\n",
    "    split_dir = Path(f'/home/user/Documents/LRS/mask/{split}')\n",
    "    image_dir = split_dir / 'images'\n",
    "    label_dir = split_dir / 'labels'\n",
    "    \n",
    "    # Create both images and labels directories\n",
    "    image_dir.mkdir(parents=True, exist_ok=True)  # Fix: Create images directory\n",
    "    label_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Process all masks in the split directory\n",
    "    for mask_path in split_dir.glob('*_mask.png'):\n",
    "        # Get corresponding image (e.g., xyz_mask.png â†’ xyz.jpg)\n",
    "        image_path = mask_path.with_name(mask_path.name.replace('_mask.png', '.jpg'))\n",
    "        \n",
    "        # Move image to images subdirectory\n",
    "        try:\n",
    "            image_path.rename(image_dir / image_path.name)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: Image {image_path} not found. Skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Generate YOLO annotation file\n",
    "        output_txt = label_dir / f\"{mask_path.stem.replace('_mask', '')}.txt\"\n",
    "        mask_to_yolo(mask_path, output_txt, class_id=0, mode='segmentation')  # Adjust mode as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation (YOLOv8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install YOLOv8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install ultralytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-seg.pt')  # Segmentation model\n",
    "model.train(data='/home/user/Documents/LRS/data.yaml', project=\"/home/user/Documents/LRS/Models\", epochs=50, imgsz=640, batch=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO('/home/user/Documents/RSI/runs/segment/train2/weights/best.pt')\n",
    "\n",
    "# Predict on a single image\n",
    "image_path = \"/home/user/Documents/LRS/mask/test/images/tile_12_jpg.rf.b0d051c082e97538bdd45a416fa6d93b.jpg\"\n",
    "results = model.predict(image_path, imgsz=640, conf=0.5)\n",
    "\n",
    "# Visualize results\n",
    "for result in results:\n",
    "    plotted = result.plot()  # Draw masks/boxes on the image\n",
    "    cv2.imshow(\"Prediction\", plotted)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
